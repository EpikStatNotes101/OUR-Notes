# Tests of Goodness of Fit
## Intro
The compatibality of a set of observed sample values with a normal distribution or any other distribution can be checked by a goodness-of-fit type of test. These are tests designed for a null hypothesis which is a statement about the form of the cumulative distribution function or probability function of the parent population from which the sample is drawn. Ideally the hypothesized distribution is completely specified, including all parameters. Since the alternative is necessarily quite broad, including differences only in location, scale, other parameters, form, or any combination thereof, rejection of the null hypothesis does not provide much specific information. Goodness-of-fit tests are customarily used when only the form of the population is in question, with the hope that the null hypothesis will be found acceptable. 

In this chapter we shall consider two types of goodness-of-fit tests. The first type is designed for null hypotheses concerning a discrete distribution and compares the observed frequencies with the frequencies expected under null hypothesis. This is the chi-square test proposed by Karl Pearson early in the history of statistics. The second type of goodness of fit test is designed for null hypotheses concerning a continous distribution and compares the observed cumulative frequencies with those expected under the null hypotheses. This group includes the *Kolmogorov-Smirnov* and the *Lilliefor's test*. 

## The Chi-Sq Goodness of Fit Test 
Let $X_1, X_2,...X_n$ be a random sample of size $n$ drawn from a population with unknown c.d.f $F_X$. We wish to test the null hypothesis
$$H_0:F_X(x)=F_0(x) \forall x$$
where $F_0(x)$ is completely specified, against the general alternative 
$$H_1:F_X(x) \neq F_0(x) \text{ for some }x$$