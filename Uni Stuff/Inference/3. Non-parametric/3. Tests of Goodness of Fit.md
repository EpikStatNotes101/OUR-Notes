# Tests of Goodness of Fit
## Intro
The compatibality of a set of observed sample values with a normal distribution or any other distribution can be checked by a goodness-of-fit type of test. These are tests designed for a null hypothesis which is a statement about the form of the cumulative distribution function or probability function of the parent population from which the sample is drawn. Ideally the hypothesized distribution is completely specified, including all parameters. Since the alternative is necessarily quite broad, including differences only in location, scale, other parameters, form, or any combination thereof, rejection of the null hypothesis does not provide much specific information. Goodness-of-fit tests are customarily used when only the form of the population is in question, with the hope that the null hypothesis will be found acceptable. 

In this chapter we shall consider two types of goodness-of-fit tests. The first type is designed for null hypotheses concerning a discrete distribution and compares the observed frequencies with the frequencies expected under null hypothesis. This is the chi-square test proposed by Karl Pearson early in the history of statistics. The second type of goodness of fit test is designed for null hypotheses concerning a continous distribution and compares the observed cumulative frequencies with those expected under the null hypotheses. This group includes the *Kolmogorov-Smirnov* and the *Lilliefor's test*. 

## The Chi-Sq Goodness of Fit Test 
Let $X_1, X_2,...X_n$ be a random sample of size $n$ drawn from a population with unknown c.d.f $F_X$. We wish to test the [[3. Hypothesis Testing#^d677e1|null hypothesis]]
$$H_0:F_X(x)=F_0(x) \forall x$$
where $F_0(x)$ is completely specified, against the general alternative 
$$H_1:F_X(x) \neq F_0(x) \text{ for some }x$$

In order to apply the chi-square test in this situation, the sample data is first grouped using some scheme to form a frequency distribution.Even though the hypothesized distibution is most likely continous with measutement data, data must be categoeized for analysis by the chi-square test.  

Let the $n$ observations be grouped into $k$ mutually exvclusive categories. Under $H_0$ we can obtain the probability $(p_i)$ of a random observation from $F_0$ to belong in the $i$th class $A_i(i=1,2,..k)$. The expected frequency in the $i$th class is $e_i=np_i$ for $i=1,2,...k$. These are compared with the observed frequencies. Pearson suggested the statitic $$Q=\sum_{i=1}^k\frac{(x_i -np_i)^2}{np_i}$$ If the agreement between the observed $(x_i)$ and expected frequencies $(e_i)$ is close, then the differences $(x_i-n_{p_i})$ and $Q$ will be small.

For large sample, $$Q\sim\chi^2_{k-1}$$ under $H_0$

Thus the [[3. Hypothesis Testing#^d677e1|null hypothesis ]] is rejected if observed $Q>\chi^2_{\alpha,k-1}$

>**Note 1** This approximation holds good if $e_i\geq5 \forall i$. Else we combine adjacent classes till the expected freq in the combined class is at least 5

<!--
Include examples
-->

