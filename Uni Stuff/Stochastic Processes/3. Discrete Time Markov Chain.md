# Discrete Time Markov Chain
Let $\left\{X_n, n\geq 0 \right\}$ be a stochastic process taking values in a state space $S$ that has $N$ states. such a stochastic process is a Markov processes if it satisfies a following property : 

$$P(X_{n+1}=k_{n+1}|X_n = k_{n}, X_{n-1} = k_{n-1},...X_{1} = k_{1})=P(X_{n+1}=k_{n+1}|X_n = k_{n})$$

For a markov process, the *future state* only depends on the *present state* and not on the *past states*. 

If the state space of a Markov process is discrete, it's called a **Markov chain**.

To understand the behaviour of this process, we will need to calculate probabilities like, 
$$P\left[X_0 = i_0, X_1 = i_1, ..., X_n = i_n\right]$$ ..(1)

$\because P(A,B)=P(A)\cdot P(B|A)$, this can be computed by multiplying conditional probabilities as follows. 

$$= P(X_0=i_0)\cdot P(X_1=i_1|X_0=i_0) \cdot P(X_2=i_2|X_1 = i_1, X_0=i_0)...$$ $$P(X_n=i_n|X_{n-1} = i_{n-1}, X_{n-2} = i_{n-2}, ..., X_0=i_0)$$ ..(2)

From the markovian property, 
$$= P(X_0=i_0)\cdot P(X_1=i_1|X_0=i_0) \cdot P(X_2=i_2|X_1 = i_1)...P(X_n=i_n|X_{n-1} = i_{n-1})$$ ..(3)

## State Transition Probabilities
For a discrete time markov chain $\left\{X_n: n=1,2,...\right\}$ with discrete state space $S=\left\{0, 1, 2, ...\right\}$ where this set may be finite or infinite, if $X_n=i$ then the markov chain is said to be in state $i$ at time $n$(or the $n^{\text{th}}$ step)

A discrete time markov chain $\left\{X_n: n=1,2,...\right\}$ is characterized by 

$$P\left[X_{n+1}=i_{n+1}|X_n=i_n,...,X_0=i_0\right]=P\left[X_{n+1}=i_{n+1}|X_n=i_n\right]$$

Where $P\left[X_{n+1}=j|X_n=i\right]$ is called one step transition probability

If $P\left[X_{n+1}=j|X_n=i\right]$ is independent of $n$ then the markov chain is said to possess stationary transition probabilities and the process is reffered to as a homogeneous markov chain. Otherwise the process is called a non-homogeneous markov chain. 

### Transition Probability Matrix

![[Uni Stuff/Stochastic Processes/Diagrams/Markov1.png]]